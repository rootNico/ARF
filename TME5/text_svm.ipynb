{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn import linear_model, svm,model_selection\n",
    "import sklearn\n",
    "from arftools import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from StringKernel import StringKernel\n",
    "from cross_validation import validation_croisee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('data/smaller_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(authors):\n",
    "    authors_sample = authors['reviewerID'].sample(2)\n",
    "    subset = authors[authors['reviewerID'].isin(authors_sample)]\n",
    "    X = subset['reviewText']\n",
    "    Y = subset['reviewerID']\n",
    "    vocab = get_vocab(X)\n",
    "    return (X,Y, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors = data[data.groupby(by='reviewerID')['reviewerID'].transform(\"count\") == 20]\n",
    "samples = [generate_sample(authors) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset = authors[authors['reviewerID'].isin(authors_sample)]\n",
    "X = subset['reviewText']\n",
    "Y = subset['reviewerID']\n",
    "X_train = X[0:20]\n",
    "Y_train = Y[0:20]\n",
    "X_test = X[20:]\n",
    "Y_test = Y[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(X_train, Y_train, X_test, vocab, lambda_param):\n",
    "    string_kernel = StringKernel().build_kernel(vocab, lambda_param)\n",
    "    precomputed_gram_matrix = string_kernel(X_train.values,X_train.values)\n",
    "    svm_instance = sklearn.svm.SVC(kernel=\"precomputed\")\n",
    "    svm_instance.fit(precomputed_gram_matrix,Y_train)\n",
    "\n",
    "    return svm_instance.predict(string_kernel(X_test.values,X_test.values))\n",
    "\n",
    "def get_vocab(X):\n",
    "    vocab = set()\n",
    "    for text in X:\n",
    "        for word in nltk.word_tokenize(text):\n",
    "            vocab.add(word)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda : 0.1\n",
      "0.633333333333\n",
      "lambda : 0.3\n",
      "0.633333333333\n",
      "lambda : 0.5\n",
      "0.633333333333\n",
      "lambda : 0.7\n",
      "0.633333333333\n",
      "lambda : 0.9\n",
      "0.633333333333\n",
      "lambda : 0.95\n",
      "0.633333333333\n",
      "lambda : 1\n",
      "0.633333333333\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "results = []\n",
    "lambdas = [0.1,0.3,0.5,0.7,0.9,0.95,1]\n",
    "for i,l in enumerate(lambdas):\n",
    "    print('lambda : ' + str(l))\n",
    "    res = []\n",
    "    for X,Y,vocab in samples:\n",
    "        prediction = train_and_test(X[0:N], Y[0:N], X[N:], vocab, l)\n",
    "        prec = (prediction == Y[N:]).sum() / N\n",
    "        res.append(prec)\n",
    "    mean = np.array(res).mean()\n",
    "    print(mean)\n",
    "    results.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032061     AJYGQV81FSFE2\n",
       "1061565     AJYGQV81FSFE2\n",
       "1089083    A1K94LXX833JTT\n",
       "1134271     AJYGQV81FSFE2\n",
       "1150190    A1K94LXX833JTT\n",
       "1165293    A1K94LXX833JTT\n",
       "1212022     AJYGQV81FSFE2\n",
       "1315945     AJYGQV81FSFE2\n",
       "138297     A1K94LXX833JTT\n",
       "140449     A1K94LXX833JTT\n",
       "1432245    A1K94LXX833JTT\n",
       "171198      AJYGQV81FSFE2\n",
       "203787     A1K94LXX833JTT\n",
       "218007     A1K94LXX833JTT\n",
       "26597      A1K94LXX833JTT\n",
       "320003      AJYGQV81FSFE2\n",
       "321596     A1K94LXX833JTT\n",
       "336274      AJYGQV81FSFE2\n",
       "49304      A1K94LXX833JTT\n",
       "531373      AJYGQV81FSFE2\n",
       "Name: reviewerID, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samutamminen/Documents/Study/Sorbonne/S2/ARF/TME/TME5/StringKernel.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return self.K(self.k, s,t) / np.sqrt(self.K(self.k, s,s) * self.K(self.k, t,t))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = StringKernel(lambda_param=1)\n",
    "kernel.K_hat('car','cat')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
