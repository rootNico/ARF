{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder une fonction entropie(vect) qui calcule l’entropie de ce vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropy import entropie, cond_entropie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropie([1,2])\n",
    "cond_entropie([[1,2],[9,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# data : tableau ( films , features ) , id2titles : dictionnaire id -> titre ,\n",
    "# fields : id feature -> nom\n",
    "[ data , id2titles , fields ]= pickle.load(open(\"imdb_extrait.pkl\",\"rb\"))\n",
    "# la derniere colonne est le vote\n",
    "datax = data [: ,:32]\n",
    "datay = np.array([1 if x [33] >6.5 else -1 for x in data ])\n",
    "\n",
    "binary_columns = data[:,:27]\n",
    "N = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = np.zeros(28)\n",
    "cond_entropies = np.zeros(28)\n",
    "for column in range(28):\n",
    "    d = data[:,column]\n",
    "    entropies[column] = entropie(d)\n",
    "    entropy_left = cond_entropie(binary_columns[np.where(d == 1)])\n",
    "    entropy_right = cond_entropie(binary_columns[np.where(d != 1)])\n",
    "    cond_entropies[column] = (np.count_nonzero(d == 1)/N) * entropy_left + (np.count_nonzero(d != 1) / N) * entropy_right\n",
    "print(entropies)\n",
    "print(cond_entropies)\n",
    "print(entropies - cond_entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decisiontree import DecisionTree\n",
    "dt = DecisionTree()\n",
    "dt.max_depth = 10\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "dt.fit(datax , datay )\n",
    "dt.predict( datax [:5 ,:])\n",
    "print(dt.score( datax , datay ))\n",
    "# dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "dt.to_pdf(\"/tmp/test_tree.pdf \",fields)\n",
    "# sinon utiliser http :// www . webgraphviz . com /\n",
    "dt.to_dot(fields)\n",
    "# ou dans la console\n",
    "print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decisiontree import DecisionTree\n",
    "dt = DecisionTree()\n",
    "scores = []\n",
    "for partition in [(0.2,0.8),(0.5,0.5),(0.8,0.2)]:\n",
    "    training_x, test_x, training_y, test_y = train_test_data(datax, datay, partition[0])\n",
    "    for depth in range(10):    \n",
    "        dt.max_depth = depth\n",
    "        dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "        dt.fit(training_x , training_y )\n",
    "        result = dt.predict(test_x)\n",
    "        scores.append(dt.score( np.array(result),test_y))\n",
    "    plt.plot(list(range(len(scores))), scores)\n",
    "    scores = []\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(x,y, partition):\n",
    "    train_n = int(len(x) * partition)\n",
    "    test_n = int(len(x) - train_n)\n",
    "    indices = np.random.permutation(len(x))\n",
    "    training_idx, test_idx = indices[:train_n], indices[test_n:]\n",
    "    return(x[training_idx,:], x[test_idx,:] ,y[training_idx], y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt = DecisionTree()\n",
    "dt.max_depth = 4\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "for partition in [(0.2,0.8),(0.5,0.5),(0.8,0.2)]:\n",
    "    training_x, test_x, training_y, test_y = train_test_data(datax, datay, partition[0])\n",
    "    dt.fit(training_x , training_y )\n",
    "    result = dt.predict(test_x)\n",
    "    print(dt.score( np.array(result) , test_y ))\n",
    "    # dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "    #dt.to_pdf(\"/tmp/test_tree.pdf \",fields)\n",
    "    # sinon utiliser http :// www . webgraphviz . com /\n",
    "    dt.to_dot(fields)\n",
    "    # ou dans la console\n",
    "    #print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[1,2],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datay)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
