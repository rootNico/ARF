{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from decisiontree import DecisionTree\n",
    "from utils import divide_intervalles, train_test_data, validation_croisee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder une fonction entropie(vect) qui calcule l’entropie de ce vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropie(vect):\n",
    "    c = Counter()\n",
    "    c.update(vect)\n",
    "    probas = np.array(list(c.values())) / len(vect)\n",
    "    return -np.array([y * np.log(y) for y in probas]).sum()\n",
    "\n",
    "def cond_entropie(list_vect):\n",
    "    res = 0\n",
    "    total = np.array([len(v) for v in list_vect]).sum()\n",
    "    for vect in list_vect:\n",
    "        res += (len(vect)/total) * entropie(vect)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17441604792151594"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropie([1,0,0]) - cond_entropie([[1,0],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4587\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# data : tableau ( films , features ) , id2titles : dictionnaire id -> titre ,\n",
    "# fields : id feature -> nom\n",
    "[ data , id2titles , fields ]= pickle.load(open(\"imdb_extrait.pkl\",\"rb\"))\n",
    "# la derniere colonne est le vote\n",
    "datax = data [: ,:32]\n",
    "datay = np.array([1 if x [33] >6.5 else -1 for x in data ])\n",
    "\n",
    "binary_columns = data[:,:27]\n",
    "N = len(data)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.391612101839 - 0.387697688437\n",
      "0.502990577458 - 0.374044947069\n",
      "0.522698604361 - 0.35440015897\n",
      "0.182577604245 - 0.457329730463\n",
      "0.133519960773 - 0.357630485379\n",
      "0.657644559269 - 0.330455741382\n",
      "0.183910571343 - 0.371167324699\n",
      "0.370626735941 - 0.31022426541\n",
      "0.0280491213059 - 0.376154061964\n",
      "-0.0 - 0\n",
      "-0.0 - 0\n",
      "-0.0 - 0\n",
      "0.631093770102 - 0.373202570113\n",
      "0.0922641395842 - 0.348361611361\n",
      "0.342591239375 - 0.388612040493\n",
      "0.00544934082635 - 0.38756701502\n",
      "-0.0 - 0\n",
      "0.693090123033 - 0.332181180594\n",
      "0.561675545181 - 0.390205234763\n",
      "0.0405061769458 - 0.236832775689\n",
      "0.122705948469 - 0.408204004216\n",
      "0.158489482929 - 0.364718390455\n",
      "0.312101795903 - 0.423542893525\n",
      "0.479345020202 - 0.406040088193\n",
      "0.356618295421 - 0.409782009541\n",
      "-0.0 - 0\n",
      "0.136548708034 - 0.338341210815\n"
     ]
    }
   ],
   "source": [
    "for attribute in range(binary_columns.shape[1]):\n",
    "    x = binary_columns[:,attribute]\n",
    "    entr = entropie(x)\n",
    "    idx = np.where(binary_columns[:, attribute] == 1)[0]\n",
    "    entr_cond = cond_entropie(binary_columns[idx])\n",
    "    print(str(entr) + \" - \" + str(entr_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821015914541\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "dt.max_depth = 10\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "dt.fit(datax , datay )\n",
    "#dt.predict( datax [:5 ,:])\n",
    "print(dt.score( datax , datay ))\n",
    "# dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "#dt.to_pdf(\"/tmp/test_tree.pdf \",fields)\n",
    "# sinon utiliser http :// www . webgraphviz . com /\n",
    "#dt.to_dot(fields)\n",
    "# ou dans la console\n",
    "#print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2, 0.8, 'r')\n",
      "(0.5, 0.5, 'b')\n",
      "(0.8, 0.2, 'g')\n"
     ]
    }
   ],
   "source": [
    "from decisiontree import DecisionTree\n",
    "for i,partition in enumerate([(0.2,0.8, 'r'),(0.5,0.5, 'b'),(0.8,0.2, 'g')]):\n",
    "    print(partition)\n",
    "    erreur_train = []\n",
    "    erreur_test = []\n",
    "    training_x, test_x, training_y, test_y = train_test_data(datax, datay, partition[0])\n",
    "    for depth in range(1,10):\n",
    "        dt = DecisionTree()\n",
    "        dt.max_depth = depth\n",
    "        dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "        dt.fit(training_x , training_y )\n",
    "        erreur_train.append(dt.score(training_x, training_y))\n",
    "        erreur_test.append(dt.score(test_x,test_y))\n",
    "    plt.figure()\n",
    "    plt.plot(list(range(len(erreur_train))), erreur_train, partition[2], label=str(partition[0]) + \" / \" + str(partition[1]))\n",
    "    plt.plot(list(range(len(erreur_test))), erreur_test, partition[2]+'-')\n",
    "    plt.xlabel(\"Maximum profondeur de l'arbre\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"partition\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le partition 0.8 / 0.2 (vert) semble d'etre le plus robust pour test et training.\n",
    "\n",
    "Quand il y a que peu d'examples d'apprentissage, l'erreur est plus éleve dans le test. Par contre quand on a beacoup des d'examples d'aprentissage, l'erreur dans le test est moins d'élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt = DecisionTree()\n",
    "dt.max_depth = 4\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "for partition in [(0.2,0.8)]:#[(0.2,0.8),(0.5,0.5),(0.8,0.2)]:\n",
    "    training_x, test_x, training_y, test_y = train_test_data(datax, datay, partition[0])\n",
    "    dt.fit(training_x , training_y )\n",
    "    print(type(training_x[0]))\n",
    "    print(type(training_y))\n",
    "    #result = dt.predict(test_x)\n",
    "    #print(dt.score( np.array(result) , test_y ))\n",
    "    # dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "    #dt.to_pdf(\"/tmp/test_tree.pdf \",fields)\n",
    "    # sinon utiliser http :// www . webgraphviz . com /\n",
    "    dt.to_dot(fields)\n",
    "    # ou dans la console\n",
    "    #print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "188 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2] + np.array([3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716807910611\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "dt.max_depth = 4\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "print(validation_croisee(datax, datay, dt, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458.7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4587 / 10"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
