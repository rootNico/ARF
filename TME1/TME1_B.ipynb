{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from decisiontree import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder une fonction entropie(vect) qui calcule l’entropie de ce vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropie(vect):\n",
    "    c = Counter()\n",
    "    c.update(vect)\n",
    "    probas = np.array(list(c.values())) / len(vect)\n",
    "    return -np.array([y * np.log(y) for y in probas]).sum()\n",
    "\n",
    "def cond_entropie(list_vect):\n",
    "    res = 0\n",
    "    total = np.array([len(v) for v in list_vect]).sum()\n",
    "    for vect in list_vect:\n",
    "        res += (len(vect)/total) * entropie(vect)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropie([1,2])\n",
    "cond_entropie([[1,6,2],[9,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# data : tableau ( films , features ) , id2titles : dictionnaire id -> titre ,\n",
    "# fields : id feature -> nom\n",
    "[ data , id2titles , fields ]= pickle.load(open(\"imdb_extrait.pkl\",\"rb\"))\n",
    "# la derniere colonne est le vote\n",
    "datax = data [: ,:32]\n",
    "datay = np.array([1 if x [33] >6.5 else -1 for x in data ])\n",
    "\n",
    "binary_columns = data[:,:27]\n",
    "N = len(data)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()\n",
    "dt.max_depth = 10\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "dt.fit(datax , datay )\n",
    "dt.predict( datax [:5 ,:])\n",
    "print(dt.score( datax , datay ))\n",
    "# dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "#dt.to_pdf(\"/tmp/test_tree.pdf \",fields)\n",
    "# sinon utiliser http :// www . webgraphviz . com /\n",
    "dt.to_dot(fields)\n",
    "# ou dans la console\n",
    "print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decisiontree import DecisionTree\n",
    "for partition in [(0.2,0.8, 'r'),(0.5,0.5, 'b'),(0.8,0.2, 'g')]:\n",
    "    print(partition)\n",
    "    erreur_train = []\n",
    "    erreur_test = []\n",
    "    training_x, test_x, training_y, test_y = train_test_data(datax, datay, partition[0])\n",
    "    for depth in range(1,10):\n",
    "        dt = DecisionTree()\n",
    "        dt.max_depth = depth\n",
    "        dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "        dt.fit(training_x , training_y )\n",
    "        erreur_train.append(dt.score(training_x, training_y))\n",
    "        erreur_test.append(dt.score(test_x,test_y))\n",
    "    plt.plot(list(range(len(erreur_train))), erreur_train, partition[2])\n",
    "    plt.plot(list(range(len(erreur_test))), erreur_test, partition[2]+'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le partition 0.8 / 0.2 (vert) semble d'etre le plus robust pour test et training.\n",
    "\n",
    "Quand il y a que peu d'examples d'apprentissage, l'erreur est plus éleve dans le test. Par contre quand on a beacoup des d'examples d'aprentissage, l'erreur dans le test est moins d'élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(x,y, partition):\n",
    "    train_n = int(len(x) * partition)\n",
    "    test_n = int(len(x) - train_n)\n",
    "    indices = np.random.permutation(len(x))\n",
    "    training_idx, test_idx = indices[:train_n], indices[test_n:]\n",
    "    return(x[training_idx,:], x[test_idx,:] ,y[training_idx], y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt = DecisionTree()\n",
    "dt.max_depth = 4\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "for partition in [(0.2,0.8)]:#[(0.2,0.8),(0.5,0.5),(0.8,0.2)]:\n",
    "    training_x, test_x, training_y, test_y = train_test_data(datax, datay, partition[0])\n",
    "    dt.fit(training_x , training_y )\n",
    "    print(type(training_x[0]))\n",
    "    print(type(training_y))\n",
    "    #result = dt.predict(test_x)\n",
    "    #print(dt.score( np.array(result) , test_y ))\n",
    "    # dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "    #dt.to_pdf(\"/tmp/test_tree.pdf \",fields)\n",
    "    # sinon utiliser http :// www . webgraphviz . com /\n",
    "    dt.to_dot(fields)\n",
    "    # ou dans la console\n",
    "    #print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_intervalles(X, Y, N):\n",
    "    assert X.shape[0] == Y.shape[0]\n",
    "    indexes = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indexes)\n",
    "    index_intevals = np.array_split(indexes, N)\n",
    "    res = np.array([(X[ind, :],Y[ind]) for ind in index_intevals])\n",
    "    return (res[:, 0], res[:, 1])\n",
    "\n",
    "def validation_croisee(X,Y, dt, N):\n",
    "    intervalles_x, intervalles_y = divide_intervalles(X,Y,N)\n",
    "    results = []\n",
    "    for i in range(N):\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        test_x = []\n",
    "        test_y = []\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                train_x.extend(intervalles_x[j])\n",
    "                train_y.extend(intervalles_y[j])\n",
    "            else:\n",
    "                test_x.extend(intervalles_x[j])\n",
    "                test_y.extend(intervalles_y[j])\n",
    "        dt.fit(np.array(train_x), np.array(train_y))\n",
    "        results.append(dt.score(np.array(test_x), np.array(test_y)))\n",
    "    return np.array(results).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "188 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2] + np.array([3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()\n",
    "dt.max_depth = 4\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "print(validation_croisee(datax, datay, dt, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4587 / 10"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
